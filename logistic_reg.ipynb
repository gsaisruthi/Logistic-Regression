{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "# sklearn is only used for making the train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "np.random.seed(9)# for using recreatability\n",
    "df = pd.read_csv('data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['variance',' skewness','curtosis','entropy']].to_numpy()\n",
    "Y = df['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization \n",
    "# using  mean and varience so that the weights don't blow up\n",
    "X_norm = np.zeros_like(X,dtype=float)\n",
    "for i in range(X[0,:].size):\n",
    "    X_norm[:,i] = (X[:,i] - X[:,i].mean()) / X[:,i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_norm, Y,stratify=Y ,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidNeuron:\n",
    "  \n",
    "  def __init__(self,reg = \"none\",loss_f = 'none',lam = 1):\n",
    "    self.w = None\n",
    "    self.b = 0\n",
    "    self.reg = reg\n",
    "    self.lam = lam\n",
    "    self.loss_f = loss_f\n",
    "    self.loss_tracing = {}\n",
    "    self.accuracy_tracking = {}\n",
    "    \n",
    "  def perceptron(self, x):\n",
    "    return np.dot(x, self.w.T) + self.b\n",
    "  \n",
    "  def sigmoid(self, x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "  \n",
    "  def grad_w(self, x, y):\n",
    "        y_pred = self.sigmoid(self.perceptron(x))\n",
    "        \n",
    "        return (y_pred - y) * y_pred * (1 - y_pred) * x\n",
    "\n",
    "  def pos_neg(self):\n",
    "          w_=np.zeros_like(self.w)\n",
    "          w = self.w.tolist()\n",
    "          \n",
    "          for j in range(len(w)):\n",
    "              \n",
    "              if w[0][j]>0:\n",
    "                  w_[j] = 1\n",
    "              else:\n",
    "                  w_[j] = -1\n",
    " \n",
    "          return np.array(w_)\n",
    "  def grad_b(self, x, y):\n",
    "    y_pred = self.sigmoid(self.perceptron(x))\n",
    "    return (y_pred - y) * y_pred * (1 - y_pred)\n",
    "\n",
    "  def accuracy_calc(self,X,Y):\n",
    "      y_pred = self.sigmoid(self.perceptron(X))\n",
    "      Y_bin = 1*(.8 <= y_pred)\n",
    "      \n",
    "      accuracy_cal = (Y_bin==Y.all()).sum()\n",
    "      return accuracy_cal/Y.size\n",
    "\n",
    "  def loss_cal(self,pred,actual):\n",
    "        \n",
    "        loss = 0\n",
    "       \n",
    "        for y,y_p in zip(pred,actual):\n",
    "            loss += (y-y_p)**2\n",
    "        \n",
    "        if self.loss_f == 'none':\n",
    "            return (loss**.5)/pred.size\n",
    "        elif self.loss_f == 'l2':\n",
    "            return ((loss**.5)+np.dot(self.w,self.w.T).item())/pred.size+np.dot(self.w,self.w.T).item()\n",
    "        elif self.loss_f == 'l1' :\n",
    "            return ((loss**.5)+np.absolute(self.w).sum())/pred.size\n",
    "  \n",
    "  def fit(self, X, Y, epochs=1, learning_rate=.1, initialise='normal', display_loss=False):\n",
    "    \n",
    "    # initialise w, b\n",
    "    if initialise == 'random':\n",
    "        self.w = np.random.rand(1, X.shape[1]) #N * 4 will create random with (1,4)\n",
    "        self.b = 0\n",
    "    elif initialise == 'normal':\n",
    "        self.w = np.random.randn(1,X.shape[1]) #N * 4 will create random with (1,4) but all number bell mean =0 std=1\n",
    "        self.b=0\n",
    "      \n",
    "    m = Y.size\n",
    "    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
    "      dw = 0 #change\n",
    "      db = 0 # change b\n",
    "for x, y in zip(X, Y):#x will be each of X(one row of X) y = corespoding row of Y\n",
    "        dw += self.grad_w(x, y)# for all points\n",
    "        db += self.grad_b(x, y) \n",
    "      if self.reg == 'l2':      \n",
    "        self.w -=   (learning_rate * self.lam) * self.w + learning_rate * (dw)\n",
    "        self.b -=  learning_rate*db\n",
    "      elif self.reg == 'l1':\n",
    "            self.w -= (learning_rate * self.lam) * self.pos_neg() + dw * learning_rate\n",
    "            self.b -=  learning_rate*db\n",
    "      else :\n",
    "            self.w -= learning_rate*dw\n",
    "            self.b -= learning_rate*db\n",
    "      \n",
    "      if display_loss:\n",
    "        Y_pred = self.sigmoid(self.perceptron(X))\n",
    "        self.loss_tracing[i] = self.loss_cal(Y_pred, Y)\n",
    "        self.accuracy_tracking[i] = self.accuracy_calc(X_test,Y_test)\n",
    "    print(\"Accuracy=\",self.accuracy_calc(X_train,Y_train))\n",
    "    if display_loss:\n",
    "        fig, (ax1, ax2) = plt.subplots(2,sharex=True)\n",
    "        fig.suptitle('Loss verses Test Acuracy')\n",
    "        ax1.plot(list(self.loss_tracing.values()))\n",
    "        ax1.set_title(\"loss v/s epoches\")\n",
    "        ax2.plot(list(self.accuracy_tracking.values()))\n",
    "        ax2.set_title(\"accuracy v/s epoches\")\n",
    "      \n",
    "      \n",
    "        plt.show()\n",
    "      \n",
    "  def predict(self, X):\n",
    "    Y_pred = []\n",
    "    for x in X:\n",
    "      y_pred = self.sigmoid(self.perceptron(x))\n",
    "      Y_pred.append(y_pred)\n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn1 = SigmoidNeuron()\n",
    "sn2 = SigmoidNeuron(reg='l2',lam = 5)\n",
    "sn3 = SigmoidNeuron(reg='l1',lam = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn1.fit(X_train,Y_train,epochs=100,learning_rate=0.015,display_loss=False)\n",
    "sn2.fit(X_train,Y_train,epochs=100,learning_rate=0.015,display_loss=False)\n",
    "sn3.fit(X_train,Y_train,epochs=100,learning_rate=0.015,display_loss=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
